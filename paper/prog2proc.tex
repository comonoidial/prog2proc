\documentclass[preprint]{sigplanconf}

\usepackage{fixltx2e}

\usepackage[english]{babel}
\usepackage{amsmath,amssymb,array,listings}
\def\codefamily{\sffamily\normalsize}
\def\codesmall{\sffamily\small}

\usepackage{xspace}

\usepackage{todonotes}

\usepackage{framed}

\usepackage{xcolor}

\usepackage{tikz}
\usetikzlibrary{positioning,fit}
\usetikzlibrary{shapes.geometric}

\def\clash{C$\lambda$aSH\xspace}

\bibliographystyle{abbrvnat}

\begin{document}
\lstset{language=Haskell, basewidth=1.2ex, basicstyle=\codefamily, identifierstyle=\itshape,
 deletekeywords={String,Maybe,Just,Nothing,map,mapM,split,bracket,when,Bool,Int,div,round,sin,maxBound,fromIntegral,odd,True,False,Eq,negate,Double,Enum,index,fromEnum,not,accum,Functor,min,max,next,lookup,const,transpose,sum,sqrt,zip,zipWith,replicate,undefined,splitAt,length,foldl1,Float,otherwise}} 

\title{Tranforming Programs into Application Specific Processors}
\authorinfo{Arjan~Boeijink \and Hendrik Folmer \and Jan~Kuper \and Marco J.G. Bekooij}{University of Twente}{\{w.a.boeijink,h.h.folmer,j.kuper\}@utwente.nl}

\maketitle

\begin{abstract}
The combination of performance and energy efficiency drives hardware designers to create specialized components for specific applications.
Current hardware technology has the space for complex algorithms to be mapped to hardware, however this complexity makes a manual hardware design process no longer tenable.
This paper shows that implementing a program as a specialised hardware design can be a systematic process using classic compiler techniques, and yields a processors-like architecture.
From programs written in an embedded Haskell DSL with explicit clock cycle boundaries we automatically generate a synthesizable hardware descriptions for application specific processors.
\end{abstract}


\section{Introduction}
after getting performance gains first from higher clock frequencies and later from increased parallelism \\
with the energy cost (either in electricy bill for data center, or battery live for mobile devices) as the main bottleneck in computing \\
raising clock frequencies is no longer an option and exploiting more parallelism is getting harder with diminishing returns \\
Specialisation as key to hardware effiency. \\
FPGAs became large enough for many applications.
%FPGAs even available as accelerators for cloud computing.

%From the outside hardware is usually a small black box with number of pins connected to it.
%The inside a of chip consists of a large numbers of transistors are connected by wires.

% Some questions after reflecting on my own research:
\begin{itemize}
 \item What is the real difference between software and hardware?
 \item Why seems instruction set design obvious in hindsight?
 \item What are the important choices in ISA/processor design?
 \item How to make processor design a more systematic process?
\end{itemize}

Functional languages have a long history with hardware design \cite{Sheeran2005}

\subsection{Hardware in Haskell using \clash}
Designing hardware architectures for FPGA is traditionally done using low-level hardware description languagles (HDLs) like Verilog or VHDL. Functional languages have a long history with hardware design \cite{Sheeran2005}. \clash \cite{Baaij} is a subset of Haskell that can be compiled to widely supported lower level HDLs. Even though you can use most abstractions that Haskell has to offer, \clash is still a structural hardware description language.
\subsection{The hardware design process in practice}
Designing hardware from a mathematical perspective using \clash is described in [TODO] and contains the following steps:
\begin{enumerate}
 \item Choose algorithm
\end{enumerate}
While choosing an algorithm it is important to keep in mind how well the target hardware could potentially solve the problem. FPGAs are suitable for reusing computational structures and consistent data streams.
\begin{enumerate}%[resume]
 \item Specify math in executable Haskell
\end{enumerate}
text..
\begin{enumerate}%[resume]
 \item Convert Haskell to \clash
\end{enumerate}
Converting the executable Haskell to executable \clash consist mainly of using fixed size vectors in stead of lists, and selecting a numeric precision for data. \clash does not support recursion so either rewrite recursion in higher-order functions or create a mealy machine structure. Once the entire design is specified the \clash -compiler can automatically generate a hardware architecture in VHDL or Verilog which can be synthesized to determine the hardware resource costs.
\begin{enumerate}%[resume]
 \item Determine resource constrains
\end{enumerate}
The synthesized architecture in \clash consumes a certain amount of hardware resources but the target device has a limited amount of resources available. These resource constrains are in terms of memory, memory bandwidth, logical elements, and digital signal processors (DSPs). There are also constrains on latency and throughput.
\begin{enumerate}%[resume]
 \item ... time-area trade-off
\end{enumerate}
There are several methods to create a feasible design for the given resource constrains. One could split the algorithm in steps to reduce data access to limit the memory bandwidth. Finding patterns in the algorithm allows for the reuse of hardware components over time. This limits both memory and computational area on an FPGA. Breaking long latency computation in parts enable faster clock frequencies which influences latency and throughput. Pipelining and multistep computation requires glue logic/control to operate. During the time-area trade-off one can iterate through all the above mentioned methods. 

The nice aspect of this process is that every step the result can be evaluated/simulated because it is executable Haskell/\clash code. In the time-area trade-off  the impact of every design choice can be evaluated. The downside of this method, especially when iteratively designing a time-area trade-off, is that it comes down to the designers knowledge which technique is necessary to make a feasible design.

Creating glue logic/control to operate the algorithm is error prone and can be complex. This paper presents a method of deducing the control- and data-path from the algorithm, given the algorithms execution order??

%\subsection{Hardware in Haskell using \clash}
%\clash \cite{Baaij} is a subset of Haskell that can be compiled to widely supported lower level hardware description languages such as Verilog and VHDL.
%Even though you can use most abstractions that Haskell has to offer, \clash is still a structural hardware description language.
%
%\subsection{The hardware design process in practice}
%\begin{enumerate}
% \item Choose algorithm
% \item Convert math/pseudo code to executable Haskell
% \item fixed size vectors
% \item select numeric precision
% \item synthesize for hardware resource costs
% \item split algorithm in steps to reduce data access to feasible memory bandwith
% \item find patterns in algorithm to enable reuse of hardware components
% \item break long latency computation in parts to enable good clock frequencies
% \item write glue logic/control for pipelining and multistep computations
% \item synthesize design for target hardware platform
% \item iterate parts of this process until satisfied with performance/costs
%\end{enumerate}
%The nice aspect of this process is that every refinement of the design is described as executable haskell code.
%Thus you can easily compare outputs of each step and see the impact of design choices on precission.
%The downside is that you often come to conclusion that the algoritm choosen doesn't achieve the performance/costs you want. So you have to go through all steps again.
%Steps 6 to 9 take the most effort, and step 9 is very error prone and can be very complex.

\section{Rewriting a program into a processor}
as a running example in this section we use a binary variant of greatest common divisor, that doesn't use any complex arithmetic operation \\
the use of multiple recursive functions and a data dependent recursion depth makes it non trivial to implement this computation in hardware
\begin{lstlisting}
binGCD :: Word32 -> Word32 -> Word32       
binGCD x 0 = x
binGCD x y = let
    a = dropZeros x
    b = dropZeros y
    (s,g) = (min a b, max a b)
  in binGCD s (g - s) <<< countZeros (x .|. y)

dropZeros :: Word32 -> Word32
dropZeros i = i >>> countZeros i

countZeros :: Word32 -> Word32
countZeros n = if odd n then 0 
  else countZeros (n >>> 1) + 1
\end{lstlisting}
the count trailing zeros could been implemented as a primitive operation as a fold over bits

\subsection{Desugaring and flattening the program}
the first step is splitting up expressions which are too complex to execute within a single clock cycle \\
this can be done by introducing let expression like in the conversion to administrative normal form \cite{ANF} \\
the question is which expressions to define as trivial, for example some arithmetic operations mights be cheap enough to keep nested \\
for this example we will split up all nested expression, in order to produce a very simple processor
\begin{lstlisting}
binGCD x y = 
  if (y == 0) then x
  else
    let a = dropZeros x in
    let b = dropZeros y in
    let g = max a b in
    let s = min a b in
    let d = g - s in
    let r = binGCD s d in
    let o = x .|. y in
    let e = countZeros o in
    r <<< e
\end{lstlisting}

\subsection{Making sequential execution explicit}
making control flow explicit using continuation passing style is a standard method in compilers for functional languages
with a flattened program we only have to introduce a continuation for the body of each let expression:
\begin{lstlisting}
binGCD x y k = if (y == 0)
  then cont x k
  else
    dropZeros x
      (\a -> dropZeros y
        (\b -> cont (max a b)
          (\g -> cont (min a b)
            (\s -> cont (g - s)
              (\d -> binGCD s d
                (\r -> cont (x .|. y)
                  (\o -> countZeros o
                    (\e -> cont (r <<< e) k)
      )))))))
\end{lstlisting}
here we use the $cont$ function to make continuation application explicit

\subsection{Defunctionalising continuations}
translating recursive functions \cite{Ingmar} \cite{Zhai} \\
CPS transform \cite{AppelCwC} \\
defunctionalisation \cite{Reynolds} \\
combined in \cite{CCC}

\lstset{basicstyle=\codesmall}
\begin{lstlisting}
data Cont
  = CA Word32 Word32                      Cont
  | CB Word32 Word32 Word32               Cont
  | CC Word32 Word32 Word32 Word32        Cont
  | CD Word32 Word32 Word32 Word32 Word32 Cont

binGCD x y         k  = if (y == 0)
                   then cont x         k
                   else dropZeros x    (CA x y       k)
cont a (CA x y     k) = dropZeros y    (CB x y a     k)
cont b (CB x y a   k) = cont (max a b) (CC x y a b   k)
cont g (CC x y a b k) = cont (min a b) (CD x y a b g k)
\end{lstlisting}
\lstset{basicstyle=\codefamily}

\subsection{State machine with a stack}
combine functions into one by making each a data type, including the continuation application function \\
using the observation that nested continuations form a stack

\begin{lstlisting}
data Call = GCD Word32 Word32 | DropZs Word32
          | CntZs Word32 | Cont Word32
data Context
  = CA Word32 Word32
  | CB Word32 Word32 Word32
  | CC Word32 Word32 Word32 Word32
  | CD Word32 Word32 Word32 Word32 Word32
  ...
type Stack  = [Context]

step :: Call -> Stack -> (Call, Stack)
step (GCD x y)        cs = if y == 0
  then (Cont x      , cs               )
  else (DropZs x    , CA x y       : cs)
step (Cont a)        (CA x y       : cs) =
     (DropZs y      , CB x y a     : cs)
step (Cont b)        (CB x y a     : cs) =
     (Cont (max a b), CC x y a b   : cs)
step (Cont g)        (CC x y a b   : cs) =
     (Cont (min a b), CD x y a b g : cs)
\end{lstlisting}

\begin{figure}
\centering
\begin{tikzpicture}
\node[draw, shape=rectangle, minimum width=6em] (st) {Call state};
\node[draw, shape=rectangle, minimum width=6em, minimum height=4em, below of=st, node distance=4em, rounded corners] (fun) {Step function};
\node[draw, shape=rectangle, minimum width=6em, below of=fun, node distance=4em] (con) {Context};
\node[draw, shape=rectangle, minimum width=6em, minimum height=9em, below of=con, node distance=6em] (ck) {stack};
\draw[densely dotted] (con.south west) -- (ck.north west);
\draw[densely dotted] (con.south east) -- (ck.north east);
\draw[->, dashed] ([yshift=0.3em]st.east) -- node[above, near end] {result} ([yshift=0.3em,xshift=6em]st.east);
\draw[<-, dashed] ([yshift=0.3em]st.west) -- node[above, near end] {input} ([yshift=0.3em,xshift=-6em]st.west);
\draw[->] ([yshift=0.5em]fun.east) -| ([xshift=2em]fun.north east) |- ([yshift=-0.3em]st.east);
\draw[->] ([yshift=-0.3em]st.west) -| ([xshift=-2em]fun.north west) |- ([yshift=0.5em]fun.west);
\draw[->] ([yshift=-0.5em]fun.east) -| ([xshift=2em]fun.south east) |- (con.east);
\draw[->] (con.west) -| ([xshift=-2em]fun.south west) |- ([yshift=-0.5em]fun.west);
\draw[<->] (con.south) -- (ck.north);
\end{tikzpicture}
\caption{Hardware structure of the stack machine}
\label{fig:stack}
\end{figure}
Figure \ref{fig:stack} shows the stack machine structure as hardware
\subsection{Separating the data stack}

lots of data copied from one state/continuation to another \\
and stack is very wide because some continuations capture a lot of free variables \\
only a few are used/produced every cycle \\
note that we have to copy the argument to the dropZeros function because they are used again and/or in the wrong order \\
for the arguments to the recursive binGCD call we can skip copying as they are in the right order and not used later

\begin{lstlisting}
data State = BinGCD | DropZs | CntZs | Cont
data Context = CA | CB | CC | CD | ...
type CtrlStack  = [Context]
type DataStack = [Word32]

step ::  State -> CtrlStack -> DataStack ->
  (State, CtrlStack, DataStack)
step BinGCD     cs      (y:x:ds) = if y == 0
  then (Cont  , cs   ,     x:ds)
  else (DropZs, CA:cs, x:y:x:ds)
step Cont (CA:cs)     (a:y:x:ds) = 
  (DropZs, CB:cs,    y:a:y:x:ds)
step Cont (CB:cs)   (b:a:y:x:ds) = 
  (Cont,   CC:cs,  g:b:a:y:x:ds) where g = max a b
step Cont (CC:cs) (g:b:a:y:x:ds) = 
  (Cont,  CD:cs, s:g:b:a:y:x:ds) where s = min a b
\end{lstlisting}

having two stacks might look like a unnecessary complication from the C-like software stack point of view, but is common in hardware designs based on Forth \cite{LaForest}

\subsection{Optimizing control}

What happens in every step can depend on both the state and top of the continuation stack. \\
combine state and continuation stack in a control stack by eliminating the Return state. \\
now only the top of the control stack directly determines what each step does. \\
the top of the control stack is effectively a program counter \\
a program counter is merely a numeric encoded label optimized for the common case of continuing at the successive label \\
the steps with if expressions are more complex than the rest, and can be split up by computing the branch condition in a separate step

\begin{lstlisting}
data Label = BinGCD | T1 | E1 | CA | CB | CC
   | CDE | DropZs | ... deriving Enum
type ControlStack  = [Label]
type DataStack = [Word32]
type CtrlFun = Label -> CtrlStack -> 
  (Label, CtrlStack)

step :: Label -> DataStack -> (CtrlFun,DataStack)
step BinGCD        (y:x:ds) =
  (branch E1 z,     y:x:ds) where z = y == 0
step T1            (y:x:ds) = 
  (ret        ,       x:ds)
step E1            (y:x:ds) = 
  (call DropZs,   x:y:x:ds)
step CA          (a:y:x:ds) = 
  (call DropZs, y:a:y:x:ds)
step CB        (b:a:y:x:ds) = 
  (next     , g:b:a:y:x:ds) where g = max a b
step CC      (g:b:a:y:x:ds) = 
  (next   , s:g:b:a:y:x:ds) where s = min a b
\end{lstlisting}

the resulting dual stack machine looks like something you could derive by looking at the flattened program from tradition imperative language point of view

\subsection{Splitting into components}

to be able to use efficient existing memory components we have to extract the use of the datastack from the step function \\
this means spliting each step in parts to seperate memory read and write actions \\
also splitting off the arithmetic operations makes it easier to reuse hardware for similiar (arithmetic) computations

\begin{lstlisting}
type CtrlFun = Word32 -> Label -> CtrlStack ->
   (Label, CtrlStack)
type Input = DataStack -> Word32
type AluOp = Word32 -> Word32 -> Word32
type StackMod = Word32 -> DataStack -> DataStack
\end{lstlisting}

\lstset{basicstyle=\codesmall}
\begin{lstlisting}
step :: Label -> (CtrlFun,Input,Input,AluOp,StackMod)
step GCD = (branch E1  ,peek 0,lit 0 , isEq ,keep)
step T1  = (ret        ,peek 1,lit 0 , pass ,popNPush 2)
step E1  = (call DropZs,peek 1,lit 0 , pass ,push)
step CA  = (call DropZs,peek 1,lit 0 , pass ,push)
step CB  = (next       ,peek 1,peek 0, max  ,push)
step CC  = (next       ,peek 2,peek 1, min  ,push)
\end{lstlisting}
\lstset{basicstyle=\codefamily}

[TODO] check if such a description would be synthesizable in \clash{}

\subsection{Control by microcode}

each step now produces a set of functions, however functions can not directly exist in hardware \\
thus we apply defunctionalisation to each component \\
the resulting structure is like a processor controlled by horizontal microcode

\begin{lstlisting}
data AluOp = Const | Add | Sub | Or | Min | Max |
   ShR | ShL | IsEq | IsOdd
data Input = S Int | I Word32
data StAction = Keep | Push | PopNPush Int
data Ctrl = Call Label |Return |Branch Label |Next
\end{lstlisting}

\lstset{basicstyle=\codesmall}
\begin{lstlisting}
microcode :: Label -> (Ctrl,Input,Input,AluOp,StAction)
microcode pc = case pc of
  BinGCD -> (Branch E1  , S 0, I 0, IsEq , Keep)
  T1     -> (Return     , S 1, I 0, Pass , PopNPush 2)
  E1     -> (Call DropZs, S 1, I 0, Pass , Push)
  CA     -> (Call DropZs, S 1, I 0, Pass , Push)
  CB     -> (Next       , S 1, S 0, Max  , Push)
  CC     -> (Next       , S 2, S 1, Min  , Push)
  CDE    -> (Call BinGCD, S 1, S 0, Sub  , Push)
  CFG    -> (Call CntZs , S 5, S 4, Or   , Push)
  CH     -> (Return     , S 1, S 0, ShL  , PopNPush 7)
  DropZs -> (Call CntZs , S 0, I 0, Pass , Push)
  CI     -> (Return     , S 1, S 0, ShR  , PopNPush 2)
  CntZs  -> (Branch E2  , S 0, I 0, IsOdd, Keep)
  T2     -> (Return     , I 0, I 0, Pass , PopNPush 1)
  E2     -> (Call CntZs , S 0, I 1, ShR  , Push)
  CK     -> (Return     , S 0, I 1, Add  , PopNPush 2)
\end{lstlisting}
\lstset{basicstyle=\codefamily}

\begin{lstlisting}
alu :: AluOp -> Word32 -> Word32 -> Word32
alu Pass  x _ = x
alu Add   x y = x + y
alu Sub   x y = x - y
alu Or    x y = x .|. y
alu Min   x y = min x y
alu Max   x y = max x y
alu ShR   x y = x >>> y
alu ShL   x y = x <<< y
alu IsEq  x y = if x == y then 1 else 0
alu IsOdd x _ = if odd x then 1 else 0

selInput :: DataStack -> Input -> Word32
selInput ds (S i) = ds !! i
selInput _  (I x) = x

stackMod :: StAction -> Word32 -> 
  DataStack -> DataStack
stackMod Keep             = keep
stackMod Push             = push
stackMod (PushAfterPop n) = pushAfterPop n

ctrl :: Ctrl -> Word32 -> Label -> [Label] ->
  (Label, [Label])
ctrl Next       = next
ctrl Return     = ret
ctrl (Branch e) = branch e
ctrl (Call f  ) = call f
\end{lstlisting}

\subsection{Synthesisable implementation in \clash}
the main effort of converting into a synthesisable hardware description is replacing the lists for the control and data stack with memory components and stack pointers \\
both stackpointers and the program counter need to be stored in a register \\
the $microcode$ and $alu$ code from previous step can be directly reused with any change \\
all components are then connected together in the toplevel of the processor description \\
this is straightforward except for having to work with Signal's instead of pure values

\begin{lstlisting}
proccesor :: Signal () -> Signal (Label, Word32)
proccesor _ = bundle (pc, z) where
  pc = register def pc'
  (ctrlOp,ia,ib,oper,stOp) = liftB microcode pc

  nPC = liftA succ pc
  (cSP', savePC, pc') = 
    liftB5 ctrl ctrlOp z nPC cSP retPC
  cSP = register 0 cSP'
  retPC = asyncRam d64 cSP savePC

  rdA = liftA2 agu dSP ia
  rdB = liftA2 agu dSP ib
  a = asyncRam d128 rdA wrData
  b = asyncRam d128 rdB wrData

  x = liftA2 inputMux ia a
  y = liftA2 inputMux ib b
  z = liftA3 alu oper x y

  dSP = register 0 dSP'
  (dSP', wrData) = liftB3 stackMod stOp dSP z
\end{lstlisting}

\begin{lstlisting}
agu :: Word8 -> Input -> Word8
agu stackSp (S i) = stackSp - i
agu stackSp (I _) = stackSp

ctrl :: Ctrl -> Word32 -> Label -> Word8 -> Label
  -> (Word8, Maybe (Word8, Label), Label)
ctrl Next       _ nPC cSP retPC =
  (cSP  , Nothing          , nPC)
ctrl Return     _ nPC cSP retPC =
  (cSP-1, Nothing          , retPC)
ctrl (Branch e) 0 nPC cSP retPC =
 (cSP  , Nothing          , e)
ctrl (Branch e) _ nPC cSP retPC =
  (cSP  , Nothing          , nPC)
ctrl (Call f)   _ nPC cSP retPC =
  (cSP+1, Just (cSP+1, nPC), f)

stackMod :: StAction -> Word8 -> Word32 ->
  (Word8, Maybe (Word8, Word32))
stackMod Keep         dSP z =
  (dSP , Nothing)
stackMod Push         dSP z =
  (dSP', Just (dSP', z)) where dSP' = dSP+1
stackMod (PopNPush n) dSP z =
  (dSP', Just (dSP', z)) where dSP' = dSP-n+1
\end{lstlisting}


\subsection{The derived hardware architecture}
\begin{figure}
\centering
\begin{tikzpicture}
\node[draw, shape=rectangle, minimum width=6em, minimum height=8em] (im) {InstrMem};
\node[draw, shape=rectangle, rounded corners, minimum width=8em, above right of=im, xshift=7em] (dec) {Decode};
\node[draw, shape=rectangle, minimum width=3em, below of=im, node distance=6.5em] (pc) {PC};
\node[draw, shape=rectangle, rounded corners, right of=pc, xshift=0.5em, inner sep=0.15em] (npc) {\begin{scriptsize}$+1$\end{scriptsize}};
\node[draw, shape=rectangle, rounded corners, right of=pc, xshift=1em, yshift=-1.5em] (cc) {\begin{small}Control\end{small}};
\node[draw, shape=rectangle, minimum width=3em, minimum height=6em, below of=pc, node distance=5.5em, align=center] (cs) {Ctrl\\stack};
\node[draw, shape=rectangle, minimum width=6em, minimum height=10em, below of=im, node distance=10em, align=center, xshift=16em] (ds) {Data\\stack};
\node[draw, shape=trapezium, minimum width=3em, minimum height=2em, below of=dec, node distance=4em, xshift=-1em, rotate=90] (alu) {};
\node[xshift=-0.5em, rotate=90] at (alu.center) {Alu};
\node[draw, shape=rectangle, rounded corners, below right of=alu, node distance=4.5em, yshift=-0.7em, inner sep=0.2em, align=center] (sp) {\begin{scriptsize}Stack\end{scriptsize}\\\begin{scriptsize}pusher\end{scriptsize}};
\draw ([yshift=0.5em] alu.south) -- ([xshift=-0.8em] alu.south) -- ([yshift=-0.5em] alu.south);
\node[draw, shape=trapezium, minimum width=1em, minimum height=0.5em, right of=alu, node distance=3em, yshift=1em, rotate=90] (ina) {};
\node[draw, shape=trapezium, minimum width=1em, minimum height=0.5em, right of=alu, node distance=2em, yshift=-1em, rotate=90] (inb) {};
\draw[->] (ina.north) -- (alu.south east);
\draw[->] (inb.north) -- (alu.south west);
\draw[->] ([xshift=1em] ds.north) |- (ina.south);
\draw[->] ([xshift=-1em] ds.north) |- (inb.south);
\draw[->] (pc.north) -- (im.south);
\draw[->] (pc.east) -- (npc.west);
\draw[->] (npc.south) -- ([xshift=-0.5em] cc.north);
\draw[->] ([yshift=1.85em] im.east) -- (dec.west);
\draw[->] ([yshift=0.3em] cc.west) -| (pc.south);
\draw[->] ([yshift=-0.3em] cc.west) -| (cs.north);
\draw[->] ([yshift=2.5em]cs.east) -| (cc.south);
\draw[->] ([yshift=0.5em] sp.east) -- ([yshift=4.45em] ds.west);
\draw[->] (alu.north) -- ([xshift=-0.5em] alu.north) |- (sp.west);
\draw[->, densely dashed] (alu.north) -- ([xshift=-0.5em] alu.north) |- (cc.east);
\draw[->, densely dotted] ([xshift=-3.5em] dec.south) -- ([xshift=1em] cc.north);
\draw[->, densely dotted] ([xshift=-1em] dec.south) -- (alu.east);
\draw[->, densely dotted] ([xshift=1em] dec.south) -- (inb.east);
\draw[->, densely dotted] ([xshift=2em] dec.south) -- (ina.east);
\draw[->, densely dotted] ([xshift=3em] dec.south) -- ([xshift=0.8em]sp.north);
\end{tikzpicture}
\caption{Architecture of derived processor}
\label{fig:proc}
\end{figure}
Figure \ref{fig:proc} shows a schematic of the derived processor architecture

\subsection{Differences with general purpose processors}

The downside of using horizontal microcode is that it costs a lot of bits to encode each step in the program \\
also writing microcode by hand is a lot of work \\
thus almost all processors define an instruction set that provides a slightly higher way of writing programs \\
from the processor point of view an instruction set is just a compressed form of microcode with a hardware component for decoding (decompressing) \\
secondly an instruction set gives the oppertunity of improving the next generation of a processor design without having to change all software

\begin{lstlisting}
instrMem :: [(Label, Instr)]
decode :: Instr->(Input,Input,Oper,StAction,Ctrl)

selInput :: DataStack -> Input -> Word32
alu :: Oper -> Word32 -> Word32 -> Word32
stackMod :: StAction->Word32->DataStack->DataStack
ctrl :: Ctrl -> Word32 -> CtrlStack -> CtrlStack

sim :: DataStack -> [Label] -> Word32
sim ds []       = top ds
sim ds (pc:cs) = sim ds' cs' where
  Just is = P.lookup pc instrMem
  (ia, ib, op, g, f) = decode is
  x = selInput ds ia
  y = selInput ds ib
  z = alu op x y 
  ds' = stackMod g z ds
  cs' = ctrl f z (pc : cs)
\end{lstlisting}

heap memory \\
pipelining \\
input/ouput 

\section{A DSL for explicitly clocked programs}
When designing application specific hardware components we care a lot about performance and/or efficiency, otherwise we could have used some existing processor.
The gains come from doing some specialised computation in less steps (clock cycles) and/or doing more operations in parallel than a normal processor could.
While the transformation process described in previous produces a working processor, it is fairly minimalistic and not that efficient.
The decision of how much computation to do in each step is a complex optimisation problem that depends on area and clock frequency requirements.
Thus we leave it up to the hardware designer to explicitly decide how to group computations into clock cycles.
Also the timing with respect to other components can be important, so the order of execution of each cycle needs to be explicit.

\subsection{Expressing control flow}
function calls \\
inline functions \\
conditional expression/statements \\
loops \\
external communication

\subsection{Mutable data and explicti memory access}
explicit allocation of writable memory addresses\\
indexing in larger memory structures \\
using arrays

\subsection{Existing components as coprocessors}
Complex arithmetic operations such as divisions, square root and trigonometric functions are usually implemented as seperate components that take many cycles to execute. \\
a coprocessor can be described as just function in the same EDSL \\
the coprocessor executes concurrently after forking it from main program, and you can wait for its finished results by joining it \\
another reason to use the coprocessor abstraction is making multiple functions execute concurrently, instead of manual interleaving each cycle of those functions

\subsection{Vectorisation support}
One of the most important ways to achieve higher performance in specialized hardware is to do a lot things in parallel.
However the amount of available parallism is often larger than what fits on the limited area of the hardware.
Thus we have split operations on large vectors into segments which are executed over time. \\

\textit{Work in progress, to be extended}


\subsection{Software pipelining}
Dependencies between operations can lead to poor utilisation of the available hardware resources.\\
If long dependencies chains exist within a loop, the performance might be improved by (partial) overlapping of the execution of multiple loop iterations. \\
This technique is known as software pipeling and is commonly used in compilers for VLIW processors.

\subsection{Cycle accurate simulation}
programs are usually part of a larger system \\
for cosimulation with other component written in \clash we support running a $Seqlogic$ program as a signal function \\
this allows whole system simulation and analysis in early stages of the design process
\begin{lstlisting}
interpretSeqLogic :: (forall s. SeqLogic s i o ())
  -> Signal (Maybe i) -> Signal (Maybe o)
\end{lstlisting}
this cycle by cycle simulation is implemented using the operational monad technique, where $clock$ statements suspend the computation \\
memory is implemented using the lazy ST monad \\
for coprocessors a list of active ones is maintained and each one is run at every $clock$ statement in the main program



\section{Example application: iterative closest point}
iterative closest point is an algorithm used for position finding using a laser range finder \cite{Robin:Hendrik}

\lstset{basicstyle=\codesmall}

\begin{lstlisting}
icp :: SeqLogic s [Float] [Float] ()
icp = do
	vecPx <- receive
	clock
	vecPy <- receive
	clock
	vecQx <- receive
	clock
	vecQy <- receive
	clock

	vecNx <- alloc (replicate 180 undefined)
	vecNy <- alloc (replicate 180 undefined)
	vecMx <- alloc (replicate 180 undefined)
	vecMy <- alloc (replicate 180 undefined)

	loop 0 (180-1) $ \i -> do
		-- get i'th value of px and replicate
		let pointX = vecPx!!i
		let vecPointX = replicate 180 pointX
		let vecDx = vecPointX .-. vecQx
		clock
		-- get i'th value of py and replicate
		let pointY = vecPy!!i
		let vecPointY = replicate 180 pointY
		let vecDy = vecPointY .-. vecQy
		clock
		let vecDx2 = vecDx .*. vecDx
		clock
		let vecDy2 = vecDy .*. vecDy
		clock
		let vecSquaredDist = vecDx2 .+. vecDy2
		clock
		let (j,k) = sortTree vecSquaredDist
		clock
		let mx0 = vecQx!!j
		let mx1 = vecQx!!k
		clock
		let my0 = vecQy!!j
		let my1 = vecQy!!k
		clock
		let (nx, ny) = createNormalVector pointX pointY mx0 my0 mx1 my1
		clock
		vecMx?i <~ mx0
		clock
		vecMy?i <~ my0
		clock
		vecNx?i <~ nx
		clock
		vecNy?i <~ ny

	v <- allocArr 4
	v0 <- use vecNx
	v?0 <~ v0
	clock
	v1 <- use vecNy
	v?1 <~ v1
	clock
	let v2'' = vecPx .*. v0
	clock
	let v2'  = vecPy .*. v1
	clock
	let v2   = v2' .+. v2''
	v?2 <~ v2
	clock
	let v3'' = vecPx .*. v1
	clock
	let v3'  = vecPy .*. v0
	clock
	let v3   = v3'' .-. v3'
	v?3 <~ v3
	clock
	vecMx' <- use vecMx
	let b'' = vecMx' .*. v0
	clock
	vecMy' <- use vecMy
	let b'  = vecMy' .*. v1
	clock
	let b   = b' .+. b''
\end{lstlisting}
	
\begin{lstlisting}
	[u0, u1, u2, u3] <- call $ qr [v0,v1,v2,v3]
-- r is the 4x4 upper triangluar matrix, q is 180x4
	u <- allocArr 4
--	t <- call $ mat_mul q' b -- t is the 4x1 vector of the sytem rx = t
	u?0 <~ u0
	clock
	u?1 <~ u1
	clock
	u?2 <~ u2
	clock
	u?3 <~ u3
	clock
	x <- allocArr 4
	linSolv <- start linearSolver
	loop 0 3 $ \j' -> let j = 3-j' in do
		u_j <- use (u?j)
		t_j <- call $ u_j `dotp` b
		infuse linSolv t_j
		loop 0 j' $ \k' -> let k = 3-k' in do
			v_k <- use (v?k)
			r_jk <- call $ u_j `dotp` v_k
			infuse linSolv r_jk
		x_j <- extract linSolv
		x?j <~ x_j
	finish linSolv
	tx <- use (x?0) -- x0 = tx
	clock
	ty <- use (x?1) -- x1 = ty
	clock
	ct <- use (x?2) -- x2 = cos theta = ct
	clock
	st <- use (x?3) -- x3 = sin theta = st 
	clock
	-- vecPx' = vecPx * ct - vecPy * st + tx
	-- vecPy' = vecPy * ct + vecPx * st + ty
	let vecPxCt = ct *. vecPx
	clock
	let vecPySt = st *. vecPy
	clock
	let vecPxCtPySt = vecPxCt .-. vecPySt
	clock
	let vecPx' = tx +. vecPxCtPySt
	clock

	let vecPyCt = ct *. vecPy
	clock
	let vecPxSt = st *. vecPx
	clock
	let vecPyCtPxSt = vecPyCt .+. vecPxSt
	clock
	let vecPy' = ty +. vecPyCtPxSt
	clock

	emit (vecPx')
	clock
	emit (vecPy')
\end{lstlisting}

solving the linear equations of an upper triangular matrix
\begin{lstlisting}
linearSolver :: SeqLogic s Float Float ()
linearSolver = do
	-- x3 = t3/r33
	t3 <- receive
	clock
	r33 <- receive
	let x3 = t3 / r33
	emit x3
	clock

	-- x2 = (t2-r23*x3)/r22	
	t2 <- receive
	clock
	r23 <- receive
	let r23x3 = r23 * x3
	clock
	let x2' = t2 - r23x3
	clock
	r22 <- receive
	let x2 = x2' / r22
	emit x2
	clock

	-- x1 = (t1 - r12x2 - r13x3) / r11
	t1 <- receive
	clock
	r13 <- receive
	let r13x3 = r13 * x3
	clock
	r12 <- receive
	let r12x2 = r12 * x2
	clock
	let x1'' = t1 - r12x2
	clock
	let x1' = x1'' - r13x3
	clock
	r11 <- receive
	let x1 = x1' / r11
	emit x1
	clock

	-- x0 = (t0 - r01x1 - r02x2 - r03x3) / r00
	t0 <- receive
	clock
	r03 <- receive
	let r03x3 = r03 * x3
	clock
	r02 <- receive
	let r02x2 = r02 * x2
	clock
	r01 <- receive
	let r01x1 = r01 * x1
	clock
	let r02x2 = r02 * x2
	clock
	let x0''' = t0 - r01x1
	clock
	let x0'' = x0''' - r02x2
	clock
	let x0' = x0'' - r03x3
	clock
	r00 <- receive
	let x0 = x0' / r00
	emit x0
	return ()
\end{lstlisting}

QR decomposition using the Gram–Schmidt process
\begin{lstlisting}
qr :: [[Float]] -> SeqLogic s [Float] [Float] [[Float]]
qr [v0,v1,v2,v3] = do
	let y0 = v0
	u0 <- call $ norm y0
	clock

	v1_u0 <- call $ v1 `dotp_scale` u0
	let y1 = v1 .-. v1_u0
	clock
	u1 <- call $ norm y1
	clock

	v2_u0 <- call $ v2 `dotp_scale` u0
	v2_u1 <- call $ v2 `dotp_scale` u1
	let sa = v2 .-. v2_u0
	clock
	let y2 = sa .-. v2_u1
	clock
	u2 <- call $ norm y2
	
	v3_u0 <- call $ v3 `dotp_scale` u0
	v3_u1 <- call $ v3 `dotp_scale` u1
	v3_u2 <- call $ v3 `dotp_scale` u2
	let sb = v3 .-. v3_u0
	clock
	let sc = sb .-. v3_u1
	clock
	let y3 = sc .-. v3_u2
	clock
	u3 <- call $ norm y3

	return [u0, u1, u2, u3]
\end{lstlisting}

\begin{lstlisting}
sortTree :: [Float] -> (Int, Int)
sortTree distances = (j,k) where 
	ids = zip distances [0..] -- annotate with index
	(part1, part2) = splitAt (div (length distances) 2) ids
	sortedLayer = zipWith (closestOfTwoPoints) part1 part2 
	(_,j,_,k) = foldl1 (closestTwoOfFourPoints) sortedLayer

-- sort two points, output is (y, iy, z, iz) where y < z
closestOfTwoPoints :: (Float,i) -> (Float,i) -> (Float,i, Float,i)
closestOfTwoPoints (a, ia) (x, ix) 
	| a < x 	= (a, ia, x, ix)
	| otherwise = (x, ix, a, ia) 

-- find the two closest distances with index out of four distances, 
-- this function can be used in a tree structure find the two closest points out a list of points
-- NOTE: assume input tuples are sorted, so a < b, and x < y
closestTwoOfFourPoints :: (Float, i, Float, i)  -> (Float, i,  Float, i) -> (Float, i, Float, i)
closestTwoOfFourPoints (a, ia, b, ib) (x, ix, y, iy) =
	case (a < x, b < x, a < y) of 
		(True, True, _) 	-> (a, ia, b, ib)
		(True, False, _)	-> (a, ia, x, ix)
		(False, _, True)	-> (x, ix, a, ia)
		(False, _, False)	-> (x, ix, y, iy)
\end{lstlisting}


\begin{lstlisting}
norm :: [Double] -> SeqLogic s i o [Double]
norm xs = do
   let sqs = xs .*. xs
   clock
   let n = sum sqs
   clock
   let invsq = 1/(sqrt n)
   clock
   return (invsq *. xs)

dotp_scale::[Double]->[Double]->SeqLogic s i o [Double]
dotp_scale vs us = do
   let zs = vs .*. us
   clock
   let n = sum zs
   clock
   return (n *. us)

dotp :: [Double] -> [Double] -> SeqLogic s i o Double
dotp xs ys = do
   let zs = xs .*. ys
   clock
   return (sum zs)

n *. xs = map (n*) xs
n +. xs = map (+n) xs
(.*.) = zipWith (*)
(.+.) = zipWith (+)
(.-.) = zipWith (-)
\end{lstlisting}

\lstset{basicstyle=\codefamily}

\subsection{Comparison with manual designed hardware}
compare hendrik implementation with the generated results from this section \\
apply high level optimizations beyond above designs

\subsection{Optimizing the ICP implementation}
software pipelining the nearest 2 points loop \\
alu output register and computation reordering to use only single memory read port

\section{Generating a processor}
source to source transformation using haskell-src-exts parser\\
input sequential logic edsl, output clash subset of haskell

\subsection{Resource requirement analysis}

first step is to find for each cycle which variables are used and which are defined and used in another cycle \\
this determines the amount of read and write ports required on the data memory, and how many inputs and outputs the ALU structure needs \\
we need to take the type of variables in account, as variables of different size may need to be stored in different memories

\subsection{Memory structure and addressing}

emulating multiport memories with blockram \\
local variables are addressed relative to the stack pointer \\
explicit allocated memory is addressed absolutely, thus not allowed in recursion functions

\subsection{Dealing with control flow}
side effect free if expressions within a cycle just become part of an alu instruction \\
problems with delays in the control path

\subsection{Optimise timing and reuse}
memory with read delay to better match with hardware \\
alu output registers with bypass for higher clocks? \\
common subexpression detection on alu expressions

\subsection{Generating \clash code}
each (co)processor in its own file \\
all declarations except for the sequential logic functions are copied

\subsection{Hardware tradeoffs}
where do constants come from? \\
storing data in registers vs. data stack memory \\
direct control vs. instruction memory \\
extra delay (register) before or after the alu to increase clock frequency

\section{Related approaches}

Feldspar \cite{Feldspar} \\
Geometry of Synthesis \cite{Ghica}

\subsection{High level synthesis}
Generates hardware from software written in ordinary programming languages (commonly C(++) or Matlab)\\
usually includes scheduling of operations \\
could describe our process as medium level synthesis

\subsection{Customisable processors}
Starting with a template of a processor to which specialised ALUs and/or coprocessors to acceralate specific algorithms \\
no instruction set processor 

\section{Conclusions}

a processor is a thing that executes programs in many bounded steps \\
merely defining the boundaries of steps to execute and their ordering is enough to derive processor like hardware structure from it

Instruction set design can be systematic refactoring process \\
The program and hardware constraints drive the steps to take \\
Besides minor optimizations only a few design choices to make \\
As a side effect derived instruction set are easy to compile for


\subsection{Future work}
implement the transformation process as GHC plugin instead of a fragile source to source compilation \\
or convince the \clash developers to integrate this in their compiler\\

Start from language semantics instead of specific programs \\
Extend for other language features (memory/complex control flow) \\
Automating parts of the process or better refactoring tools\\
Work out the process for pipelining and data parallelism? 

Generating hardware for controllers from software specification \\
Assist in designing application specific processors \\
Eventually integration into a behavioural synthesis tools?



\begin{acks}
The first author conducted this research within the Modern project (647.000.003) supported by NWO.
\end{acks}

\bibliography{p2p}

\end{document}
